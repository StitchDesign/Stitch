//
//  LLMActionRecording.swift
//  Stitch
//
//  Created by Christian J Clampitt on 6/27/24.
//

import Foundation
import StitchSchemaKit


// MARK: recording user's actions in app as a JSON of LLM Step Actions, assigning a natural language prompt and writing JSON + prompt to file

let LLM_START_RECORDING_SF_SYMBOL = "play.fill"
let LLM_STOP_RECORDING_SF_SYMBOL = "stop.fill"

struct LLMRecordingToggled: GraphEvent {
    
    func handle(state: GraphState) {
        guard let document = state.documentDelegate else {
            fatalErrorIfDebug()
            return
        }
        
        let wasInAIMode = state.graphUI.insertNodeMenuState.isFromAIGeneration
        
        // Check if we're transitioning from AI generation to recording
        if wasInAIMode {
            print("ðŸ”„ ðŸ¤– TRANSITIONING FROM AI MODE TO RECORDING - ENTERING AUGMENTATION MODE ðŸ¤– ðŸ”„")
            // Changed: Store actions before clearing AI generation state
            let currentActions = document.llmRecording.actions
            document.llmRecording.mode = .augmentation
            document.llmRecording.lastAIGeneratedActions = currentActions.asJSONDisplay()
            print("ðŸ¤– ðŸ’¾ Generated Actions: \(document.llmRecording.lastAIGeneratedActions) ðŸ’¾ ðŸ¤–")
            
            // Clear the AI generation flag since we're now in recording mode
            state.graphUI.insertNodeMenuState.isFromAIGeneration = false
            print("ðŸ”„ ðŸ¤– AI Generation Mode Cleared - Now in Recording Mode ðŸ¤– ðŸ”„")
        }
        
        if document.llmRecording.isRecording {
            let modeLabel = document.llmRecording.mode == .augmentation ? "AUGMENTATION" : "NORMAL"
            print("ðŸ“¼ ðŸ›‘ STOPPING LLM RECORDING MODE [\(modeLabel)] ðŸ›‘ ðŸ“¼")
            document.llmRecordingEnded()
        } else {
            let modeLabel = document.llmRecording.mode == .augmentation ? "AUGMENTATION" : "NORMAL"
            let transitionNote = wasInAIMode ? " (Transitioned from AI Generation)" : ""
            print("ðŸ“¼ â–¶\u{fef} STARTING LLM RECORDING MODE [\(modeLabel)]\(transitionNote) â–¶\u{fef} ðŸ“¼")
            document.llmRecordingStarted()
        }
    }
}

/// What we write to JSON/JSONL file
struct LLMRecordingData: Equatable, Encodable {
    let actions: LLMStepActions
    let prompt: String // user-entered
}

extension StitchDocumentViewModel {
    
    @MainActor
    func llmRecordingStarted() {
        print("ðŸ“¼ âš¡ï¸ LLM Recording Started - isRecording set to true âš¡ï¸ ðŸ“¼")
        
        // Added: Debug print current actions before starting recording
        print("ðŸ¤– Current Actions at Recording Start: \(self.llmRecording.actions.asJSONDisplay())")
        
        self.llmRecording.isRecording = true
    }
    
    @MainActor
    func llmRecordingEnded() {
        print("ðŸ“¼ âš¡ï¸ LLM Recording Ended - isRecording set to false âš¡ï¸ ðŸ“¼")
        self.llmRecording.isRecording = false
        
        // Added: Debug print actions before caching
        print("ðŸ¤– Current Actions at Recording End: \(self.llmRecording.actions.asJSONDisplay())")
        
        // Cache the json of the actions; else TextField changes cause constant encoding and thus json-order changes
        self.llmRecording.promptState.actionsAsDisplayString = self.llmRecording.actions.asJSONDisplay()
        
        // If we stopped recording and have LLMActions, show the prompt
        if !self.llmRecording.actions.isEmpty {
            print("ðŸ“¼ ðŸ“ Opening LLM Recording Prompt Modal ðŸ“ ðŸ“¼")
            self.llmRecording.promptState.showModal = true
            self.graphUI.reduxFocusedField = .llmRecordingModal
        }
    }
    
    // When prompt modal is closed, we write the JSON of prompt + actions to file.
    @MainActor func closedLLMRecordingPrompt() {
        print("ðŸ“¼ ðŸ’¾ Closing LLM Recording Prompt - Saving Data ðŸ’¾ ðŸ“¼")
        
        self.llmRecording.promptState.showModal = false
        self.graphUI.reduxFocusedField = nil
        
        let actions = self.llmRecording.actions
        
        guard !actions.isEmpty else {
            print("ðŸ“¼ âš ï¸ No actions to save - Resetting recording state âš ï¸ ðŸ“¼")
            self.llmRecording = .init()
            return
        }
        
        // Write the JSONL/YAML to file
        let recordedData = LLMRecordingData(actions: actions,
                                            prompt: self.llmRecording.promptState.prompt)
        
        if !recordedData.actions.isEmpty {
            Task {
                do {
                    let data = try JSONEncoder().encode(recordedData)
                    
                    let docsURL = StitchFileManager.documentsURL
                    let dataCollectionURL = docsURL.appendingPathComponent(LLM_COLLECTION_DIRECTORY)
                    
                    let dateFormatter = DateFormatter()
                    dateFormatter.dateFormat = "yyyy-MM-dd HH:mm:ss"
                    let formattedDate = dateFormatter.string(from: Date())
                    let filename = "\(self.graph.name)_\(self.graph.id)_\(formattedDate).json"
                    let url = dataCollectionURL.appendingPathComponent(filename)
                    
                    if !FileManager.default.fileExists(atPath: dataCollectionURL.path) {
                        try FileManager.default.createDirectory(
                            at: dataCollectionURL,
                            withIntermediateDirectories: true)
                    }
                    
                    try data.write(to: url, options: [.atomic, .completeFileProtection])
                    
                    print("ðŸ“¼ â¬†ï¸ Uploading recording data to Supabase â¬†ï¸ ðŸ“¼")
                    try await SupabaseManager.shared.uploadLLMRecording(recordedData)
                    print("ðŸ“¼ âœ… Data successfully saved locally and uploaded to Supabase âœ… ðŸ“¼")
                    
                } catch let encodingError as EncodingError {
                    print("ðŸ“¼ âŒ Encoding error: \(encodingError.localizedDescription) âŒ ðŸ“¼")
                } catch let fileError as NSError {
                    print("ðŸ“¼ âŒ File system error: \(fileError.localizedDescription) âŒ ðŸ“¼")
                } catch {
                    print("ðŸ“¼ âŒ Error: \(error.localizedDescription) âŒ ðŸ“¼")
                }
            }
        }
    
        print("ðŸ“¼ ðŸ”„ Resetting LLM Recording State ðŸ”„ ðŸ“¼")
        self.llmRecording = .init()
    }
}

struct LLMRecordingModeEnabledChanged: StitchStoreEvent {
    
    let enabled: Bool
    
    func handle(store: StitchStore) -> ReframeResponse<NoState> {
        log("LLMRecordingModeSet: enabled: \(enabled)")
        store.llmRecordingModeEnabled = enabled
        
        // Also update the UserDefaults:
        UserDefaults.standard.setValue(
            enabled,
            forKey: LLM_RECORDING_MODE_KEY_NAME)
        
        return .noChange
    }
}
